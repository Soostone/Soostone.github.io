{"0": {
    "doc": "About",
    "title": "About",
    "content": "# Napkin ## Intro Napkin Wiki is a collection of HOWTOs and tutorials about the tool assisting data scientists when they crunch data through their relational and NoSQL DBs. ## About Napkin app Napkin is an command line interface application and also a library Haskell library. Napkin goal is to make data scientist daily routine easier, so there are many parallel features bundled together: 1. A SQL wrapper in Haskell geared towards Redshift and therefore Postgres. * The general idea is to be able to express any hand-written SQL, no matter how complex, directly in Haskell via types and a structure that mirror SQL directly. * The Untyped folder coupled with Napkin.Types has all the types and operations to represent SQL expresions - i.e. the columns in a SQL query. * The Render folder is all about (pretty)printing queries into their final SQL form. * The Untyped.Monad module provides a simple monadic interface to constructing queries. 2. A SQL runner with some basic support for running queries on Postgres and Redshift. 3. A Spec orchestrator that allows for expression of chains of table/view creations, updates and re-creations with interdependencies that are automatically managed. * Entire SQL based computation pipelines can be expressed this way and have their periodic updates managed automatically by the framework. * Specs are necessarily stateful; we currently persist metadata in a local sqlite3 database, which can be migrated to a more serious database solution. 4. A command line interface that can take Specs and provide convenient flags for forcing certain table updates, skipping others, etc. ## [Continue with **Getting Started**](/getting-started) ",
    "url": "/about/",
    "relUrl": "/about/"
  },"1": {
    "doc": "Getting Started",
    "title": "Getting Started",
    "content": "# Getting Started ## Installation **Napkin** app is available in 2 forms: [live installer](#live-installer) and [dockerized version](#docker-version). ### Live installer Live installer is a self extracting and self contained SHELL archive, which doesn't require docker nor nix environment. As for now live installer [repository](https://soostone-napkin-public.s3.us-east-1.amazonaws.com/index.html){:target=\"_blank\" rel=\"noopener\"} has versions for Mac OS Big Sur and Linux based distros. Find a page corresponding to your environment, copy installation snipped and executed it locally. Let's say you run Mac, the latest build for MacOS Big Sur: {% include codeCaption.html label=\"shell\" %} ```sh curl -s https://soostone-napkin-public.s3.us-east-1.amazonaws.com/x86_64-MacOS-20.5.0/last-build/napkin-live-installer.sh \\ | bash -s -- ``` {: .copiable } The bundle is very fat and it contains all dependencies. If you need access to `ghci` - supply file pattern for derivations with apps you are interested in: {% include codeCaption.html label=\"shell\" %} ```sh curl -s https://soostone-napkin-public.s3.us-east-1.amazonaws.com/x86_64-MacOS-20.5.0/last-build/napkin-live-installer.sh \\ | bash -s -- -e '*-ghc-*' ``` {: .copiable } ghc derivation contains **ghci-8.10.4**. Pathes to napkin and all ghc apps are goin to be imported through `$PATH` variable. Don't forget to start new shell session to update `$PATH` variable or you can benefit from `exec $SHELL` trick. #### Uninstallation Napkin Live installer provides an uninstaller too. Type `uninstall-` and use tab to auto-complete script doing napkin uninstallation. {% include codeCaption.html label=\"shell\" %} ```sh $ uninstall- $ uninstall-b82gj7f0igpw23sapafxifsrr0f52771-napkin-0.3.8.sh ``` ### Docker version Live installer is great, because it is very lightweight, but it is not available on [Windows](https://en.wikipedia.org/wiki/Microsoft_Windows) yet. There are tutorials on the Internet for setting up [Nix](https://nixos.wiki/wiki/Nix) with [WSL](https://en.wikipedia.org/wiki/Windows_Subsystem_for_Linux) on Windows. ## Hello world Napkin has lots of interesting features and the toolset is constantlly growing. We have a bold roadmap for years! Let's consider a killer feature, which is isolated and has a pretty simple user interface. Detection unused [CTE](https://en.wikipedia.org/wiki/Hierarchical_and_recursive_queries_in_SQL#Common_table_expression) columns. Some table columns are introduced for debugging and development purpose, but as time goes an engineer can stop using them and completely forget, meanwhile such columns contribute into cost of running queries. napkin tools has command line interface. List available commands with `--help`. {% include codeCaption.html label=\"shell\" %} ```sh $ napkin --help ``` {: .copiable } ``` Usage: napkin [-v|--verbose] COMMAND Cli tool to work with Napkin ... find-unused-cte-columns Parse SQL file and find unused CTE columns ... ``` Detailed help for `find-unused-cte-columns` command: {% include codeCaption.html label=\"shell\" %} ```sh napkin find-unused-cte-columns --help ``` {: .copiable } ``` Usage: napkin find-unused-cte-columns (-b|--backend ARG) (-f|--sql-file ARG) Parse SQL file and find unused CTE columns Available options: -b,--backend ARG choose kind of SQL - BigQueryBackend or PostgresqlBackend -f,--sql-file ARG path to sql file ``` Help syntax is same for the rest of commands. Let's check following query for unused columns in an intermediate CTE table: {% include codeCaption.html label=\"query.sql\" %} ```sql with CTE as (select f, g from DbTable) select f from CTE ``` {: .copiable } {% include codeCaption.html label=\"shell\" %} ```sh napkin find-unused-cte-columns -b PostgresqlBackend -f query.sql {\"CTE\":[\"g\"]} ``` {: .copiable } To deal with a set of SQL files - generate a spec file, sort of a project file: {% include codeCaption.html label=\"shell\" %} ```sh cp query.sql query2.sql mkdir sql mv query.sql query2.sql sql napkin generate-spec -d sql # Generated spec file at: specs/spec.yaml cat specs/spec.yaml | grep source # source: query.sql source: query2.sql mv sql specs # Tiny workaround - might not be needed in the future napkin optimize ``` {: .copiable } ``` Table: [query] query, CTE \"CTE\" has unused columns [\"g\"] Table: [query2] query2, CTE \"CTE\" has unused columns [\"g\"] ``` ## [continue with tutorial](/tutorial) ",
    "url": "/getting-started/",
    "relUrl": "/getting-started/"
  },"2": {
    "doc": "Haddock",
    "title": "Haddock",
    "content": "# Haddock ## Docs for versions * [Version 0.3.8]({{site.haddock_url}}/app-version/index.html) ## Docs for branches * [last build]({{site.haddock_url}}/last-build/index.html) * [master]({{site.haddock_url}}/branch/master/index.html) * [Full list of branches with haddoc]({{site.haddock_url}}/branch/index.html) ",
    "url": "/haddock/",
    "relUrl": "/haddock/"
  },"3": {
    "doc": "Tutorial",
    "title": "Tutorial",
    "content": "1. TOC {:toc} # Tutorial ## Spec project Napkin project is called **Spec**. It is [a YAML file](https://en.wikipedia.org/wiki/YAML) enumerating [SQL](https://en.wikipedia.org/wiki/SQL)/[NoSQL](https://en.wikipedia.org/wiki/NoSQL) tables in a [DB](https://en.wikipedia.org/wiki/Database). These tables comprise an implicit [DAG](https://en.wikipedia.org/wiki/Directed_acyclic_graph), where edges are references to fields from other tables. Usually *source tables* are real tables/materialized views enfilled independently with data by other applications or as a result of manual manipulations with tables through *pgsql* e.g. Their data prexist from Napkin point of view. Napkin is a tool for describing observable, reproducable and adjustable way of refining raw data from source tables and storing them into *sink ones*. A typical sink table is an opposite to source one. It could be empty and don't event exist in a DB at the time Napkin gets hands dirty. A sink table is described by a selecting SQL query referring source tables. \"The road to truth has many turns.\" and getting data for sink tables at one step could be hard. Usually it is easier to extract from an onion style query several intermediate subqueries and refer to them as tables. These intermediate materialized tables give greater space for maneuvering and serve as cache, plus intermediate tables could be reused in other sink tables. Materialized subqueries is a greate way for debuggin and introspection. ## Sales DB demo Napkin Spec file has lots of fields and the easiest way to start a project for a beginner is to leverage a spec generator feature. All it needs is a bunch of SQL files with 1 query per file. For a model case let's consider a sales DB with following tables: ### Schema and Input Data {% include codeCaption.html label=\"input-schema.sql\" %} ```sql create table product ( id int primary key, price int not null, name text not null); create table sale( id int primary key, quantity int not null, product_id int not null); ``` {: .copiable } {% include codeCaption.html label=\"shell\" %} ```sh $ psql -f input-schema.sql salesDb ``` Data Napkin is going to consume: {% include codeCaption.html label=\"input-data.sql\" %} ```sql insert into product values (1, 2, 'chocolate bar'), (2, 3, 'coke'), (3, 50, 'kale'); insert into sale values (1, 1000, 1), (2, 2, 3), (3, 300, 2), (4, 10, 3); ``` {: .copiable } {% include codeCaption.html label=\"shell\" %} ```sh psql -f input-data.sql salesDb ``` {: .copiable } ### Napkin Queries Place sink tables in sql sub folder, they are going to be used for spec generation. {% include codeCaption.html label=\"sql/best-seller.sql\" %} ```sql select product_id, sum(quantity) from sale group by product_id order by sum(quantity) desc; ``` {: .copiable } {% include codeCaption.html label=\"sql/best-revenue.sql\" %} ```sql select product_id, sum(p.price * s.quantity) from sale s inner join product p on (s.product_id = p.id) group by product_id order by 2 desc; ``` {: .copiable } Create a spec out of queries above. It is easy to run these queries manually, but our goal now is to grasp Napkin basics, because Napkin knows correct order for executing such queries, which have dependencies between themselves. {% include codeCaption.html label=\"shell\" %} ```sql napkin generate-spec -d sql -o spec.yaml mkdir specs mv sql spec.yaml specs ``` {: .copiable } Have a look at head of spec.yaml: {% include codeCaption.html label=\"spec.yaml\" %} ```yaml sql_folder: sql db_url: postgres:/// haskell_packages: [] backend: Postgres haskell: null tables: ``` Correct `db_url`, for my local case I have: ```yaml db_url: postgresql:/user:123@127.0.0.1/salesDb ``` ``` Keepking passwords in a common configuration file is a bad idea. You can provide password through `--connectionURL` command line option. See `--help` for more details. ``` {: .info} Everything is ready for calling Napkin master command: {% include codeCaption.html label=\"shell\" %} ```sh $ napkin run --spec-file specs/spec.yaml ``` {: .copiable } ``` NOTICE: table \"best-revenue\" does not exist, skipping NOTICE: table \"best-seller\" does not exist, skipping [2021-08-20 17:25:14] Table \"best-revenue\" ran in 0.03s: 3 rows affected [2021-08-20 17:25:14] Table \"best-seller\" ran in 0.04s: 3 rows affected [2021-08-20 17:25:14] Run complete. Total cost: 6 rows affected ``` Check DB - a few new tables appeared (`best-seller`and `best-revenue`): {% include codeCaption.html label=\"psql salesDb\" %} ```sql select * from \"best-seller\"; ``` {: .copiable } ``` product_id | sum ------------+------ 1 | 1000 2 | 300 3 | 12 ``` Napkin created tables for your queries, evaluated them and persisted results. Let's modify input data pushing on kale and rerun Napkin: {% include codeCaption.html label=\"psql salesDb\" %} ```sql insert into sale values (5, 999, 3); ``` {: .copiable } {% include codeCaption.html label=\"shell\" %} ```sh napkin run --spec-file specs/spec.yaml ``` {: .copiable } {% include codeCaption.html label=\"psql salesDb\" %} ```sql select * from \"best-seller\"; ``` {: .copiable } ``` product_id | sum ------------+------ 3 | 1011 1 | 1000 2 | 300 ``` See `best-seller` is updated with kale on the top. We started with very simple schema - ids instead of numbers look ugly. How about to make sink tables more human readable? {% include codeCaption.html label=\"sql/best-seller.sql version: 2\" %} ```sql select p.name, p.price, sum(quantity) from sale s inner join product p on (s.product_id = p.id) group by product_id order by 3 desc; ``` {: .copiable } Schema table is updated automatically: {% include codeCaption.html label=\"psql salesDb\" %} ```sql select * from \"best-seller\"; ``` {: .copiable } ``` name | price | sum ---------------+-------+------ kale | 5 | 1011 chocolate bar | 2 | 1000 coke | 3 | 300 ``` ## Backends Napkin supports following backends: * [Postgres](https://www.postgresql.org/) * [BigQuery](https://cloud.google.com/bigquery) * [Redshift](https://aws.amazon.com/redshift) Napkin backend is a some DB management systems with tables. There are dozens of popular DB managements systems, so tells us what system, as a Napkin backend, you would like to see next. ## BigQuery OAuth authentication. ## Embedded Haskell Lot's of programs have embedded scripting langauge for better flexibility and automating complex business logic, recall - [VBA](https://en.wikipedia.org/wiki/Visual_Basic_for_Applications), [Emacs Lisp](https://en.wikipedia.org/wiki/Emacs_Lisp), [MaxScript](https://en.wikipedia.org/wiki/Autodesk_3ds_Max), etc and Napkin is on the same line with them and Napkin Api is available through [Haskell](https://en.wikipedia.org/wiki/Haskell_(programming_language)). ### Evaluation Haskell through **eval** Napkin eval command can interpret a set of free form Haskell modules - just specify top function you are intereseted in. Module with a lazy string function: ```haskell module Hello where import Prelude (String, (++), Char) pureStr :: String pureStr = \"Hello World!!!\" ``` ```sh $ napkin eval -f pureStr -m Hello -r . -i Pure str Hello World!!! ``` See help for calling IO action. Access to plain Haskell interpeter is a test environment for code to be used in spec for describing tables. ",
    "url": "/tutorial/",
    "relUrl": "/tutorial/"
  },"4": {
    "doc": "User Manual",
    "title": "User Manual",
    "content": "# User Manual ",
    "url": "/user-manual/",
    "relUrl": "/user-manual/"
  }
}
